% Intermediate level - handcraft feature
@inproceedings{nakano2006,
  author    = {Tomoyasu Nakano and Masataka Goto and Yuzuru Hiraga},
  title     = {An automatic singing skill evaluation method for unknown melodies
               using pitch interval accuracy and vibrato features},
  booktitle = {{INTERSPEECH} 2006 - ICSLP, Ninth International Conference on Spoken
               Language Processing, Pittsburgh, PA, USA, September 17-21},
  publisher = {{ISCA}},
  year      = {2006},
  timestamp = {Fri, 11 Mar 2011 14:41:35 +0100},
  biburl    = {https://dblp.org/rec/conf/interspeech/NakanoGH06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{knight2011,
  title     = {The potential for automatic assessment of trumpet tone quality},
  author    = {Trevor Knight and Finn Upham and Ichiro Fujinaga},
  year      = {2011},
  url       = {http://ismir2011.ismir.net/papers/PS4-17.pdf},
  researchr = {https://researchr.org/publication/KnightUF11},
  cites     = {0},
  citedby   = {0},
  pages     = {573-578},
  booktitle = {Proceedings of the 12th International Society for Music Information Retrieval Conference, ISMIR 2011, Miami, Florida, USA, October 24-28, 2011},
  editor    = {Anssi Klapuri and Colby Leider},
  publisher = {University of Miami},
  isbn      = {978-0-615-54865-4}
}
@incollection{dittmar2012,
  author    = {Christian Dittmar and Estefan{\'i}a Cano and Jakob Abe{\ss}er and Sascha Grollmisch},
  title     = {{Music Information Retrieval Meets Music Education}},
  booktitle = {Multimodal Music Processing},
  pages     = {95--120},
  series    = {Dagstuhl Follow-Ups},
  isbn      = {978-3-939897-37-8},
  issn      = {1868-8977},
  year      = {2012},
  volume    = {3},
  editor    = {Meinard M{\"u}ller and Masataka Goto and Markus Schedl},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  address   = {Dagstuhl, Germany},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2012/3468},
  urn       = {urn:nbn:de:0030-drops-34689},
  doi       = {10.4230/DFU.Vol3.11041.95},
  annote    = {Keywords: Music learning, music transcription, source separation, performance feedback}
}
@article{romani2015,
  author  = {romani picas, oriol and  parra rodriguez, hector and  dabiri, dara and  tokuda, hiroshi and  hariya, wataru and  oishi, koji and  serra, xavier},
  journal = {journal of the audio engineering society},
  title   = {a real-time system for measuring sound goodness in instrumental sounds},
  year    = {2015},
  volume  = {},
  number  = {},
  pages   = {},
  doi     = {},
  month   = {may}
}
@inproceedings{bogdanov2013,
  title     = {Essentia: An Audio Analysis Library for Music Information Retrieval},
  author    = {Dmitry Bogdanov and Nicolas Wack and Emilia Gómez and Sankalp Gulati and Perfecto Herrera and Oscar Mayor and Gerard Roma and Justin Salamon and José R. Zapata and Xavier Serra},
  year      = {2013},
  url       = {http://www.ppgia.pucpr.br/ismir2013/wp-content/uploads/2013/09/177_Paper.pdf},
  researchr = {https://researchr.org/publication/BogdanovWGGHMRSZS13-0},
  cites     = {0},
  citedby   = {0},
  pages     = {493-498},
  booktitle = {Proceedings of the 14th International Society for Music Information Retrieval Conference, ISMIR 2013, Curitiba, Brazil, November 4-8, 2013},
  editor    = {Alceu de Souza Britto Jr. and Fabien Gouyon and Simon Dixon},
  isbn      = {978-0-615-90065-0}
}
@inproceedings{vidwans2017,
  title        = {Objective descriptors for the assessment of student music performances},
  author       = {Vidwans, Amruta and Gururani, Siddharth and Wu, Chih-Wei and Subramanian, Vinod and Swaminathan, Rupak Vignesh and Lerch, Alexander},
  booktitle    = {Audio Engineering Society Conference: 2017 AES International Conference on Semantic Audio},
  year         = {2017},
  organization = {Audio Engineering Society}
}									
@inproceedings{gururani2018,
  title     = {Analysis of Objective Descriptors for Music Performance Assessment},
  author    = {Gururani, Siddharth and Pati, Kumar Ashis and Wu, Chih-Wei and Alexander Lerch},
  year      = {2018},
  url       = {http://www.musicinformatics.gatech.edu/wp-content_nondefault/uploads/2018/06/Gururani-et-al.-2018-Analysis-of-Objective-Descriptors-for-Music-Perfor.pdf},
  researchr = {https://researchr.org/publication/gururanianalysis2018},
  cites     = {0},
  citedby   = {0},
  booktitle = {Proceedings of the International Conference on Music Perception and Cognition ({ICMPC})},
  address   = {Toronto, Ontario, Canada}
}
@article{giraldo2019,
  author   = {Giraldo, Sergio and Waddell, George and Nou, Ignasi and Ortega, Ariadna and Mayor, Oscar and Perez, Alfonso and Williamon, Aaron and Ramirez, Rafael},
  title    = {Automatic Assessment of Tone Quality in Violin Music Performance},
  journal  = {Frontiers in Psychology},
  volume   = {10},
  year     = {2019},
  url      = {https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00334},
  doi      = {10.3389/fpsyg.2019.00334},
  issn     = {1664-1078},
  abstract = {The automatic assessment of music performance has become an area of increasing interest due to the growing number of technology-enhanced music learning systems. In most of these systems, the assessment of musical performance is based on pitch and onset accuracy, but very few pay attention to other important aspects of performance, such as sound quality or timbre. This is particularly true in violin education, where the quality of timbre plays a significant role in the assessment of musical performances. However, obtaining quantifiable criteria for the assessment of timbre quality is challenging, as it relies on consensus among the subjective interpretations of experts. We present an approach to assess the quality of timbre in violin performances using machine learning techniques. We collected audio recordings of several tone qualities and performed perceptual tests to find correlations among different timbre dimensions. We processed the audio recordings to extract acoustic features for training tone-quality models. Correlations among the extracted features were analyzed and feature information for discriminating different timbre qualities were investigated. A real-time feedback system designed for pedagogical use was implemented in which users can train their own timbre models to assess and receive feedback on their performances.}
}